# File Structure

#### Report.ipynb
This file contains the report on my pipeline including the docker-compose.yml file and comments under each command explaining my thought process or the command as well as the questions asked and answered.

#### datafile.json
The datafile that was downloaded from the instructions below.

#### docker-compose.yml
The docker-compose file that hosts the configuration for the pipeline

#### pyspark_commands.txt
This file contains all the pyspark commands that I ran over the course of the project.

#### sample-history.txt
This file is the updated history of all commands I ran in my terminal to reate the pipeline and explore the data.

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Description

In this project I worked with sample data from an education tech company and completed the following tasks to create and sample data pipeline for use by the analytics team. In a real world scenario this would be used by Data Scientists/Analysts to discover new trends in the product and suggest concrete improvements. This pipeline facilitates the experimentation and innovation process.

- Publish and consume messages with Kafka
- Used Spark to transform the messages. 
- Used Spark to transform the messages so that you can land them in HDFS
